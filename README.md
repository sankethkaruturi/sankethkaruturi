 <h1 align = "center"><img src="https://github.com/sankethkaruturi/Images/blob/dbf70d3bc3796ce972a3f56795c25aa0958fbc2c/animat-campfire-color.gif" width="75" />Hi there, I'm Sanketh Karuturi ğŸ‘‹</h1>

[![](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/sanketh-karuturi?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3BtFZmCwWeRMa81sHbv9Qg6w%3D%3D) [![](https://img.shields.io/badge/Kaggle-20BEFF?style=for-the-badge&logo=Kaggle&logoColor=white)](https://www.kaggle.com/sankethkaruturi)  [![](https://img.shields.io/badge/Quora-%23B92B27.svg?&style=for-the-badge&logo=Quora&logoColor=white)](https://www.quora.com/profile/Sanketh-Karuturi-1) [![](https://img.shields.io/badge/Discord-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/nMEzDt8v) [![](https://img.shields.io/badge/Zoom-2D8CFF?style=for-the-badge&logo=zoom&logoColor=white)](https://us05web.zoom.us/j/*******940?pwd=ngSO2tbJnugrEmkE9w2iJTbc5OZvbb.1) [![](https://img.shields.io/badge/Google%20Meet-32A350?style=for-the-badge&logo=google-meet&logoColor=white)](https://meet.google.com/yqb-dyvf-rfm) ![](	https://img.shields.io/badge/Slack-4A154B?style=for-the-badge&logo=slack&logoColor=white) [![](https://img.shields.io/badge/WhatsApp-25D366?style=for-the-badge&logo=whatsapp&logoColor=white)](https://api.whatsapp.com/send?phone=+14582728625)

I'm deeply passionate about  __Artificial Intelligence__,  __Machine Learning__, __Deep Learning__, __Large Language Models (LLMs)__ and __Generative AI__. 

The fast-paced growth in computational capabilities, combined with the accessibility of massive datasets, continues to drive groundbreaking progress in the AI landscape.

![](  )

<h2> ğŸ‘¨â€ğŸ“ğŸ™‹â€â™‚ï¸ About Me ğŸ’¼ğŸ’: </h2>

I earned my Masters Degree in Computer Science at [__Oregon State University__](https://oregonstate.edu/).

I bring 3+ years of hands-on experience in designing, training, and deploying __machine learning__ and __deep learning models__.

In addition, I have a solid foundationâ€”both theoretical and practicalâ€”in developing and deploying Large Language Models (LLMs) and working on Generative AI projects.

ğŸ”­ Below are some of the companies I have worked:

* *Discovery Analytics Inc, Atlanta, Georgia, USA*
* *Oregon State University, Corvallis, Oregon, USA*
* *Pentachrome Technologies Pvt Ltd, Client : KPIT, Bengaluru, Karnataka, India*
* *AEQUS Aerospace, Belagavi, Karnataka, India*

ğŸ”­ Some of the notable courses I have completed and that helped in gaining strong theoretical foundation include: 
* *Machine Learning Certification by [__Stanford University__](https://www.stanford.edu/)*
* *Deep Learning Specialization by [__Andrew Ng__](https://www.andrewng.org/)*
* *Deploying AI & Machine Learning Models for Business from [__Udemy__](https://www.udemy.com/)*
* *Python for Time Series Data Analysis by [__Jose Portilla__](https://www.udemy.com/user/joseportilla/)*

ğŸ”­ I've used different Machine Learning and Deep Learning models in real-time projects. Below are some used models:

* *Linear Regression*
* *Logistic Regression*
* *Support Vector Machines (SVM)*
* *Decision Trees (DT)*
* *Random Forests (RF)*
* *K-Nearest Neighbors (KNN)*
* *Deep Neural Networks*
* *Convolutional Neural Networks (CNN)*
* *Recurrent Neural Networks (RNN)*
* *Naive Bayes (NB)*
* *Gradient Boosted Decision Trees (GBDT)*
* *XGBoost*
* *Long Short-Term Memory (LSTM)*

ğŸ”­ Below are some state-of-the-art (SOTA) time series forecasting models used in various real-time projects: 

* *Auto-Regressive (AR) Model*
* *Auto-Regressive Moving Averages (ARMA) Model*
* *Auto-Regressive Integrated Moving Averages (ARIMA) Model*
* *Vector AutoRegression (VAR)*
* *Neural Hierarchical Interpolation of Time Series (N-HiTS) Model*
* *Seasonal Auto-Regressive Integrated Moving Averages (SARIMA) Model*
* *Temporal Fusion Transformers (TFT)*

ğŸ”­ Furthermore, below are some of the tools used during my experience for __Generative AI__:

* *Langchain*
* *LangGraph*
* *Llama Index*
* *Retrieval Augmented Generation (RAG)*
* *OpenAI API (ChatGPT, Whisper, DALLÂ·E, etc.)*
* *HuggingFace Transformers*
* *Mixtral (LLM)*
* *LLaMA 2 / LLaMA 3 (Meta AI)*
* *GPT-4.5 / GPT-4o / GPT-o1*
* *Claude Opus 4*
* *Gemini (Google DeepMind)*

ğŸ”­ Here are some of the skillsets in regards to __DevOps__ technologies:

* *Docker*
* *Docker-Compose*
* *Kubernetes*
* *Linux*
* *Jenkins*
* *Windows Subsystem for Linux (WSL)*
* *Travis CI*
* *Ubuntu*
* *GitLab CI/CD*
* *MLflow (ML model lifecycle)*
* *AWS / GCP / Azure DevOps*

![]()


<h2>ğŸªšğŸ”§ My Skills ğŸ˜€ğŸ˜€:</h2>

These tools and frameworks have significantly contributed to my ability to understand and implement complex machine learning systems.

[![](https://img.shields.io/badge/Python-FFD43B?style=for-the-badge&logo=python&logoColor=darkgreen)](https://www.python.org)  [![](https://img.shields.io/badge/TensorFlow-FF6F00?style=for-the-badge&logo=TensorFlow&logoColor=white)](https://www.tensorflow.org) [![](https://img.shields.io/badge/scikit_learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white)](https://scikit-learn.org/stable/) [![](https://img.shields.io/badge/SciPy-654FF0?style=for-the-badge&logo=SciPy&logoColor=white)](https://www.scipy.org) [![](https://img.shields.io/badge/Numpy-777BB4?style=for-the-badge&logo=numpy&logoColor=white)](https://numpy.org) [![](https://img.shields.io/badge/Pandas-2C2D72?style=for-the-badge&logo=pandas&logoColor=white)](https://pandas.pydata.org)  [![](https://img.shields.io/badge/Plotly-239120?style=for-the-badge&logo=plotly&logoColor=white)](https://plotly.com)   [![](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=PyTorch&logoColor=white)](https://pytorch.org) [<img src = "https://img.shields.io/badge/MongoDB-4EA94B?style=for-the-badge&logo=mongodb&logoColor=white"/>](https://www.mongodb.com/) [![](https://img.shields.io/badge/R-276DC3?style=for-the-badge&logo=r&logoColor=white)](https://www.r-project.org) [![](https://img.shields.io/badge/Scala-DC322F?style=for-the-badge&logo=scala&logoColor=white)](https://www.scala-lang.org) [![](https://img.shields.io/badge/json-5E5C5C?style=for-the-badge&logo=json&logoColor=white)](https://www.json.org/json-en.html) [![](https://img.shields.io/badge/Tableau-E97627?style=for-the-badge&logo=Tableau&logoColor=white)](https://www.tableau.com) [![](https://img.shields.io/badge/C-00599C?style=for-the-badge&logo=c&logoColor=white)](https://www.cprogramming.com) [![](https://img.shields.io/badge/Keras-D00000?style=for-the-badge&logo=Keras&logoColor=white)](https://keras.io) [![](https://img.shields.io/badge/MySQL-00000F?style=for-the-badge&logo=mysql&logoColor=white)](https://www.mysql.com) [![](https://img.shields.io/badge/conda-342B029.svg?&style=for-the-badge&logo=anaconda&logoColor=white)](https://www.anaconda.com) [![](https://img.shields.io/badge/PowerBI-F2C811?style=for-the-badge&logo=Power%20BI&logoColor=white)](https://powerbi.microsoft.com/en-us/) [![](https://img.shields.io/badge/Colab-F9AB00?style=for-the-badge&logo=googlecolab&color=525252)](https://colab.research.google.com) [<img src = "https://img.shields.io/badge/SQLite-07405E?style=for-the-badge&logo=sqlite&logoColor=white" width = "100" height = "27.5"/>](https://www.sqlite.org/index.html)[![](https://img.shields.io/badge/LaTeX-47A141?style=for-the-badge&logo=LaTeX&logoColor=white)](https://www.latex-project.org) [![](https://img.shields.io/badge/Java-ED8B00?style=for-the-badge&logo=java&logoColor=white)](https://www.java.com/en/) [![](https://img.shields.io/badge/Microsoft_Excel-217346?style=for-the-badge&logo=microsoft-excel&logoColor=white)](https://www.microsoft.com/en-us/microsoft-365/excel) [![](https://img.shields.io/badge/Microsoft_PowerPoint-B7472A?style=for-the-badge&logo=microsoft-powerpoint&logoColor=white)](https://www.microsoft.com/en-us/microsoft-365/powerpoint) [![](https://img.shields.io/badge/Microsoft_Office-D83B01?style=for-the-badge&logo=microsoft-office&logoColor=white)](https://www.office.com)

## ğŸ¬ğŸ“  My GitHub Summary: 

```diff
+ The images are downloaded and used thanks to https://unsplash.com/ and https://giphy.com/ websites. ğŸ™‚
```

## ğŸ’¼ğŸ’ My Portfolio Overview:

I encourage you to explore my machine learning and deep learning projects. The links are provided below, along with detailed descriptions at the bottom of this website. 

<img src = "https://github.com/sankethkaruturi/Images/blob/ff179c14b50a4b6cd913f79c9bef0d2916edec42/kari-shea-1SAnrIxw5OY-unsplash.jpg">

<h2 align = "center"> ğŸ–¥ My Generative AI Projects </h2> 

| ğŸ¤– [Medico Health Assistant ChatBot ](https://github.com/sankethkaruturi/Medico-Health-Assistant-ChatBot.git)| ğŸ‘• [Fashion GAN(Generative Adversarial Networks) ](https://github.com/sankethkaruturi/Fashion-GAN.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/63f99a65f1640ada7741890d8295933fad96ff35/ant-rozetsky-TXzdrCTdggE-unsplash.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Medico-Health-Assistant-ChatBot.git)| [<img src = "https://github.com/sankethkaruturi/Images/blob/1b8a3784d00b45b2210aaf683f1e9482e93fa047/Project%20Thumbnails/FashionGAN.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Fashion-GAN.git)| 

<h2 align = "center"> ğŸ–¥ My Machine Learning Projects </h2> 

| ğŸš [Airbnb House Prices Prediction](https://github.com/sankethkaruturi/Airbnb-House-Price-Prediction-.git)| [â˜ï¸ __Telco Customer Churn Prediction__](https://github.com/sankethkaruturi/Telco-Customer-Churn-Prediction.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/401ad2d9b93f7224ed595706d58070efc5c2fadb/clay-banks-kiv1ggvkgQk-unsplash.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Airbnb-House-Price-Prediction-.git)| [<img src = "https://github.com/sankethkaruturi/Images/blob/401ad2d9b93f7224ed595706d58070efc5c2fadb/markus-spiske-BGq8mTlzL6g-unsplash.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Telco-Customer-Churn-Prediction.git)|

| ğŸ¦ [Predicting Loan Default](https://github.com/sankethkaruturi/Loan-Default-Prediction.git)| ğŸ«€ [Heart Disease Prediction](https://github.com/sankethkaruturi/Heart-Disease-Prediction.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/bc6a2d5d1d26ef40a66334fcc59ae37fc9432208/Loan_default_prediction.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Loan-Default-Prediction.git)| [<img src = "https://github.com/sankethkaruturi/Images/blob/96e50dfae3f39dcb55ce1777282a696d9e134990/Heart_disease_Prediction.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Heart-Disease-Prediction.git)

| ğŸš´â€ [Washington Bike Demand Prediction](https://github.com/sankethkaruturi/Washington-Bike-Demand-Prediction.git)| ğŸš™ [Car Prices Prediction](https://github.com/sankethkaruturi/Car-Price-Prediction.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/bdaba15a7d48fc1ba574c90ac48f928119dd80e9/bike_demand_image.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Washington-Bike-Demand-Prediction.git)| [<img src="https://github.com/sankethkaruturi/Images/blob/0d10d3cd41a25ae5d9da916c0aabada35fe38616/car_price_prediction_image.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Car-Price-Prediction.git)

<hr style="border:0.01px solid blue">

<h2 align = "center"> ğŸ–¥ My Healthcare Projects </h2> 

| ğŸ’Š [Medicine Recommendation System](https://github.com/sankethkaruturi/Medicine-Recommendation-System-Using-Machine-Learning.git)| ğŸ§  [Brain Tumor Detection](https://github.com/sankethkaruturi/Brain-Tumor-Detection-Using-Deep-Learning.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/a5746c256803f6fa92a845582790989a7d5725fd/medicine.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Medicine-Recommendation-System-Using-Machine-Learning.git)| [<img src = "https://github.com/sankethkaruturi/Images/blob/5b79a9ac519c795b79050a36996935841d8c874e/Project%20Thumbnails/Brain%20Tumor.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Brain-Tumor-Detection-Using-Deep-Learning.git)|

| ğŸ¦ [Predicting Loan Default](https://github.com/sankethkaruturi/Loan-Default-Prediction.git)| ğŸ«€ [Heart Disease Prediction](https://github.com/sankethkaruturi/Heart-Disease-Prediction.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/bc6a2d5d1d26ef40a66334fcc59ae37fc9432208/Loan_default_prediction.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Loan-Default-Prediction.git)| [<img src = "https://github.com/sankethkaruturi/Images/blob/96e50dfae3f39dcb55ce1777282a696d9e134990/Heart_disease_Prediction.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Heart-Disease-Prediction.git)

| ğŸš´â€ [Washington Bike Demand Prediction](https://github.com/sankethkaruturi/Washington-Bike-Demand-Prediction.git)| ğŸš™ [Car Prices Prediction](https://github.com/sankethkaruturi/Car-Price-Prediction.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/bdaba15a7d48fc1ba574c90ac48f928119dd80e9/bike_demand_image.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Washington-Bike-Demand-Prediction.git)| [<img src="https://github.com/sankethkaruturi/Images/blob/0d10d3cd41a25ae5d9da916c0aabada35fe38616/car_price_prediction_image.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Car-Price-Prediction.git)

<hr style="border:0.01px solid blue">

<h2 align = "center"> ğŸ–¥ My Natural Language Processing (NLP) Projects</h2> 

| ğŸ— [Fake News Prediction](https://github.com/sankethkaruturi/Fake-News-Detection.git)| ğŸ—£ï¸ [Twitter Sentiment Analysis](https://github.com/sankethkaruturi/Twitter-Sentiment-Analysis.git) |
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/1cd9392cc60e7eff76f86b29a77abd22e990fecd/hartono-creative-studio-HQhgbdwHmSM-unsplash.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Fake-News-Detection.git)| [<img src="https://github.com/sankethkaruturi/Images/blob/96168d458a5779309160e2b170ea6035997fc7fb/boliviainteligente-FnWQJfyB-TA-unsplash.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Twitter-Sentiment-Analysis.git)|

| ğŸ“š [Predicting Readability of Texts](https://github.com/sankethkaruturi/Predicting-Readability-of-Texts-Using-Machine-Learning.git)| ğŸ” [Automated Essay Scoring with Transformers](https://github.com/sankethkaruturi/Automated-Essay-Scoring-AES-Using-Transformers.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/17366f99ca4dd9e0cc54ec07179d05d8af1cefa2/Readability_of_texts/ROTP_thumbnail.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Predicting-Readability-of-Texts-Using-Machine-Learning.git)| [<img src="https://github.com/sankethkaruturi/Images/blob/41eadc30f71ed548573171a79876ac9042e99539/Automated%20Essay%20Scoring/essay_scoring.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Automated-Essay-Scoring-AES-Using-Transformers.git)|

<hr style="border:0.01px solid blue">

<h2 align = "center"> ğŸ–¥ My Computer Vision Projects</h2>

| ğŸ‹ [Semantic Segmentation of Satellite Images using U-Net](https://github.com/sankethkaruturi/Semantic-Segmentation-of-Satellite-Images-using-U-Net.git)| ğŸ”¢ [Wheat Disease Detection Using Transfer Learning](https://github.com/sankethkaruturi/Wheat-Disease-Detection-Using-Deep-and-Transfer-Learning.git)| 
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/5b9c6fe5dd207669176b66510a3dae53314c57e3/image-25-768x512.jpeg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Semantic-Segmentation-of-Satellite-Images-using-U-Net.git)| [<img src = "https://github.com/sankethkaruturi/Images/blob/1db5fe5b8215db3430002342e357e8bd40324cf2/polina-rytova-1dGMs4hhcVA-unsplash.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Wheat-Disease-Detection-Using-Deep-and-Transfer-Learning.git)|

| ğŸ”¢ [MNIST Digits Classification](https://github.com/sankethkaruturi/MNIST-Digits-Classification.git)| ğŸ•¸ [Convolutional Neural Networks CNN Implementation Using Keras](https://github.com/sankethkaruturi/Convolutional-Neural-Network-CNN-Implementation-using-Keras.git)|
| :-:| :-:|
| [<img src = "https://github.com/sankethkaruturi/Images/blob/719248b514cae8482b3a3cdaa07f9e21d57c9c04/MNIST%20Digits%20Classification/MNIST_Digits.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/MNIST-Digits-Classification.git)| [<img src="https://github.com/sankethkaruturi/Images/blob/26ec5cf737f8c026e0229d8fdafa61c65cbb795a/Convolutional%20Neural%20Network/CNN.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Convolutional-Neural-Network-CNN-Implementation-using-Keras.git)|

| ğŸŒ¾ [Wheat Localization With Convolutional Neural Networks (CNNs)](https://github.com/sankethkaruturi/Wheat-Localization-with-CNN-s.git)| ğŸ¥„ [Steel Defect Detection](https://github.com/sankethkaruturi/Steel-Defect-Detection-.git)|
| :-:| :-:| 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/8f6e2619029165d3be3de260c24b9dc8df19a88c/Project%20Thumbnails/WL.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Wheat-Localization-with-CNN-s.git)| [<img src="https://github.com/sankethkaruturi/Images/blob/8cde2559ae4ef2a0859500f51172ba1aa6ea4f13/Project%20Thumbnails/STDFD.jpg" height = 300 width = 500/>](https://github.com/sankethkaruturi/Steel-Defect-Detection-.git)|

<h2 align = "center"> ğŸ–¥ My SQL Projects</h2> 

| ğŸš• [Cab Reservation System](https://github.com/sankethkaruturi/Cab-Reservation-System.git)|
| :-: |
| [<img src = "https://github.com/sankethkaruturi/Images/blob/ee2cb9c49bb023d940022a46bfb5d76ec0f9a2e9/Project%20Thumbnails/taxigif.gif" width = 500 height = 300/>](https://github.com/sankethkaruturi/Cab-Reservation-System.git)|

<hr style="border:0.01px solid blue">

<h2 align = "center"> ğŸ–¥ My Web Scraping Projects</h2>

| ğŸ¿ [IMDB Movies Web Scraping](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/IMDB%20web%20scraping%20.ipynb)| ğŸ” [Restaurant Recipes Web Scraping XML](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/Recipes%20XML%20querying.ipynb)|
| :-: | :-: | 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/592b8288d3ac30726f2fff1ee70844e8616720dc/bucharest-romania-july-30th-2024-top-10-list-trendy-movies-imdb-page.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/IMDB%20web%20scraping%20.ipynb) | [<img src = "https://github.com/sankethkaruturi/Images/blob/5a7e0e14475ad0e85a724510e2ff37943d3124b8/top-view-delicious-cooked-vegetables-sliced-with-different-seasonings-dark-background-soup-food-sauce-meal-vegetable.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/Recipes%20XML%20querying.ipynb)|

| ğŸ® [Popular Gaming Titles Wikipedia Web Scraping](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/Webscraping%20of%20Popular%20Gaming%20Titles%20Wikipedia.ipynb)| ğŸ” [JSON file Web Scraping](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/Json%20File%20Reading%20.ipynb) |
| :-: | :-: | 
| [<img src = "https://github.com/sankethkaruturi/Images/blob/fc09e9ba6264507e1219f0901944575bb17102ba/2149829151.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/Webscraping%20of%20Popular%20Gaming%20Titles%20Wikipedia.ipynb) | [<img src = "https://github.com/sankethkaruturi/Images/blob/5a7e0e14475ad0e85a724510e2ff37943d3124b8/programming-background-collage.jpg" width = 500 height = 300/>](https://github.com/sankethkaruturi/Web-Scraping-Projects/blob/54863c0023e166b1b28452b7821d396ed8aea6ae/Json%20File%20Reading%20.ipynb)|

<hr style="border:0.01px solid blue">


## ğŸ–¥ My Work Experience 

&emsp;&emsp; ğŸ‘¨â€ğŸ«ğŸ§‘â€ğŸ« [__Generative AI Engineer__]() | [__Discovery Analytics__]() [*June 2025 - Present*]

&emsp;&emsp; ğŸ‘¨â€ğŸ«ğŸ§‘â€ğŸ« [__UIT(University IT Dept) Student Employee__]() | [__Oregon State University__](https://oregonstate.edu/) [*October 2022 - March 2025*]

&emsp;&emsp; ğŸ¢ğŸ‘¨â€ğŸ’» [__Machine Learning Engineer__]() | [__Pentachrome Technologies Private Limited, Client: KPIT__](https://www.kpit.com/) [*August 2019 - August 2022*]

&emsp;&emsp; ğŸ§ªğŸ‘¨â€ğŸ”¬ [__AI Intern__]() | [__AEQUS Aerospace__](https://www.aequs.com/) [*January 2020 - March 2020*]


## ğŸ–¥ My Education 

&emsp;&emsp; ğŸ« [__Oregon State University__](https://oregonstate.edu/) - *Masters in Computer Science*

&emsp;&emsp; ğŸ« [__KLE Technological University, Hubli__]([http://www.vnrvjiet.ac.in/](https://www.kletech.ac.in/)) - *Bachelor of Engineering*

&emsp;&emsp; ğŸ« [__Chetan PU college, Hubli__]([https://www.narayanagroup.com](http://www.chetancollege.co.in/)) - *Pre-University College*

&emsp;&emsp; ğŸ« [__Hari Vidyalaya, Mysore__]((https://harividyalaya.in/)) - *High School*


## ğŸ–¥ My List of Certifications

&emsp;&emsp; ğŸŒ± [__Machine Learning by Stanford University__ ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; ğŸŒ± [__Deep Learning Specialization__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Neural Networks and Deep Learning__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Structuring Machine Learning Projects__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization__ ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white)]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Convolutional Neural Networks__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; ğŸŒ± [__Machine Learning with python (IBM)__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Sequence Models__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; ğŸŒ± [__Python for Data Science and Machine Learning__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]()

&emsp;&emsp; ğŸŒ± [__Data Science and Machine Learning Bootcamp with R__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]()

&emsp;&emsp; ğŸŒ± [__Machine Learning Engineering for Production (MLOps) Specialization__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Introduction to Machine Learning in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Machine Learning Data Lifecycle in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Machine Learning Modeling Pipelines in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; &emsp;&emsp; ğŸ [__Deploying Machine Learning Models in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]()

&emsp;&emsp; ğŸŒ± [__Complete Tensorflow 2 and Keras Deep Learning Bootcamp__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]() 

&emsp;&emsp; ğŸŒ± [__Deploying AI & Machine Learning Models for Business | Python__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]()

&emsp;&emsp; ğŸŒ± [__Python for Time Series Data Analysis__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]()


## ğŸ–¥ My Competencies

&emsp;&emsp; ğŸ¦¸ [__Leadership Skills__]()

&emsp;&emsp; ğŸ¦¸ [__Communication Skills__]() 

&emsp;&emsp; ğŸ¦¸ [__Creativity__]() 

&emsp;&emsp; ğŸ¦¸ [__Collaboration__]() 

&emsp;&emsp; ğŸ¦¸ [__Curiosity__]()

&emsp;&emsp; ğŸ¦¸ [__Problem-solving Skills__]()

&emsp;&emsp; ğŸ¦¸ [__Time Management__]()


## ğŸ–¥ My Blogs On Medium

&emsp;&emsp; ğŸ“ƒ [__Understanding Machine Learning: A Beginner-Friendly Guide__](https://medium.com/@sankethkaruturi09/understanding-machine-learning-a-beginner-friendly-guide-092bb42e4768)

&emsp;&emsp; ğŸ“ƒ [__A Comprehensive Guide to the K-Nearest Neighbors (k-NN) Algorithm__](https://medium.com/@sankethkaruturi09/a-comprehensive-guide-to-the-k-nearest-neighbors-k-nn-algorithm-eaaa90dc25e8)

&emsp;&emsp; ğŸ“ƒ [__Introduction to CNN(Convolutional Neural Networks)__](https://medium.com/@sankethkaruturi09/introduction-to-cnn-convolutional-neural-networks-0612b2a6d638)

&emsp;&emsp; ğŸ“ƒ [__Mathematics for Deep Learning Part 1: Linear Algebra â€” Sets, Scalars, Vectors, Matrices and Tensors__](https://medium.com/@sankethkaruturi09/mathematics-for-deep-learning-part-1-linear-algebra-sets-scalars-vectors-matrices-and-tensors-f391ccc69de7)


## ğŸ–¥ My Kaggle Profile 

I'm very familiar with __Kaggle__ - a website that would help __machine learning__ and __deep learning engineers__ to explore the enomorous amount of data and perform machine learning and deep learning predictions. I take my time to go through the kaggle projects which gives me a good idea about the working of deep learning models. Furthermore, I would read others' code as a result of which I get a good understanding of the various ways in which a deep learning project could be implemented. Below is a list of all the work that I did in __Kaggle__. Feel free to take a look and give your feedback! Thanks. 

&emsp;&emsp; ğŸ”— https://medium.com/@sankethkaruturi09

## ğŸ–¥ My Resume 

&emsp;&emsp; ğŸ“„ [__Sanketh_Karuturi Resume_2025__](https://github.com/sankethkaruturi/My-Portfolio/blob/0f09371361ee13a151344acd5456a33938c4df03/Sanketh%20Karuturi%20Resume.pdf)


## ğŸ–¥ My Contact Information

&emsp;&emsp; ğŸ“« __Email:__ __sankethkaruturi09@gmail.com__

&emsp;&emsp; ğŸ–‡ __LinkedIn:__ __https://www.linkedin.com/in/sanketh-karuturi__

&emsp;&emsp; âœğŸ» __Medium:__ __https://medium.com/@sankethkaruturi09__

&emsp;&emsp; ğŸ’» __Kaggle:__ __https://www.kaggle.com/sankethkaruturi7__

## ğŸ“”ğŸ““My InspirationğŸ˜€ğŸ˜€:

<img src = "https://github.com/sankethkaruturi/Images/blob/28f69d79b48ee59127ee33050fbd99cc3f89ff7a/Project%20Thumbnails/github%20inspiration%20image.jpg"/>

My interest in machine learning and artificial intelligence began when I was in my final year of a Bachelor of Engineering program. I suggested to my teammates that we work on a machine learning project in __healthcare__, specifically using it to predict the chances of a person suffering from heart disease. We were able to download a dataset from [__Kaggle__](https://www.kaggle.com/) and implement machine learning models to make predictions. 

The results on the test set were promising, and this sparked my interest in finding more ways to apply machine learning. I have since taken courses in machine learning, including Andrew Ng's __Machine Learning__ and __Deep Learning Specialization__ and have worked on various artificial intelligence projects in healthcare, academia, and the retail industry. Some of these projects involved data analysis and visualization to gain insights.


## ğŸ“„ğŸ“‰Blogs on Medium:

ğŸ“ Furthermore, I also write articles and share my blogs through [__Medium__](https://medium.com/). It is a website where writers could share their thoughts with the community through publications. I've written articles on Machine Learning and Deep Learning. Below is the link to my Medium articles. https://medium.com/@sankethkaruturi09

  
## ğŸ¤–âš™ï¸ My Machine Learning Projects

<img src = "https://github.com/sankethkaruturi/Images/blob/02433824a1aee5439bdcbf5c70405897789a4b49/Machine%20Learning%20Ai%20GIF%20by%20GIGABYTE%20Technology.gif" width = "750"/>

In this section, different sets of machine learning projects are highlighted. Feel free to click on the links for the projects that are highlighted. There is a brief description of the projects along with useful definitions. In the next few sections, a subset of Artificial Intelligence such as __Computer Vision__ and __Natural Language Processing (NLP)__ would be covered along with Data Visualization.

ğŸš´â€â™‚ï¸ [__Washington Bike Demand Prediction__](https://github.com/sankethkaruturi/Washington-Bike-Demand-Prediction.git) 

* In this project, the demand for rental bikes was predicted using different machine learning and deep learning algorithms.
*  Moreover, some of the useful features were __visualized__.
*  Dependencies between features were highlighted and a __correlation matrix__ was plotted to get an understanding of the relationship between features.
*  Subsequently, machine learning predictions were executed to ensure accurate outputs for the corresponding test set.

<hr style="border:0.01px solid blue">

ğŸš™ [__Car Prices Prediction__](https://github.com/sankethkaruturi/Car-Price-Prediction.git) 

* In this machine learning project, the prices of cars would be predicted based on features such as Horsepower (HP), Mileage, Make, and other features.
* Most of the project contains visualizations followed by machine learning and deep learning algorithm predictions.
* Based on the prices determined by the algorithms, companies could set the price for the cars which would result in __high profitability__. 

<hr style="border:0.01px solid blue">

ğŸ¦ [__Predicting Loan Default Using Machine Learning__](https://github.com/sankethkaruturi/Loan-Default-Prediction.git) 

* It is important for banks to give loans to customers based on their ability to pay back a loan.
* Occasionally, banks encounter situations where they grant loans to individuals who fail to repay the borrowed funds, including the accrued interest.
* Machine Learning could be used in order to determine whether a loan must be given to a person, and this would help the financial institutions and banks to save money respectively.
* In the project, various features such as income levels and the amount of loan taken were considered as features for predicting whether a person would be paying back a loan or not.
* Since the data that was taken contained a lot of __NULL__ values, various imputation methods were used such as __mean__, __median__, and __mode__ imputation.

<hr style="border:0.01px solid blue">

ğŸ«€ [__Heart Disease Prediction Using Machine Learning and Deep Learning__](https://github.com/sankethkaruturi/Heart-Disease-Prediction.git)    

* There are features that are important to predict heart disease in a patient such as __Blood Pressure (BP)__, __BMI__ and other factors.
* Since doctors cannot take into account all the factors and suggest whether a person may or may not have heart disease, it is time to use machine learning and deep learning algorithms to the rescue.
* In this machine learning project, various features such as __BMI__, __Cholesterol__, and other factors are considered for predicting the chances of a person suffering from heart disease.
* Various machine learning models were used for the predictions and their __precision__, __recall__, and __accuracy__ were plotted respectively.

<hr style="border:0.01px solid blue">

ğŸš [__Airbnb Home Prices Prediction__](https://github.com/sankethkaruturi/Airbnb-House-Price-Prediction-.git)

* Features such as neighborhood, longitute and latitude could be used to determine the prices of __Airbnb__ houses for hosts.
* __Data Science__ and __Machine Learning__ could be used to extract these insights from data and also make useful predictions for housing prices.
* Since the demand is also an important factor to consider, it becomes really interesting how the prices would vary based on this feature and many others.
* __Exploratory Data Analysis (EDA)__ was performed to take a look at features that make the highest impact when determining the prices of houses along with others.

<hr style="border:0.01px solid blue">

[â˜ï¸ __Telco Customer Churn Prediction__](https://github.com/sankethkaruturi/Telco-Customer-Churn-Prediction.git)

* Worked on predicting the __churn rate__ of customers based on factors such as age, location, and the type of service that was chosen by the customers. 
* __Exploratory Data Analysis (EDA)__ was conducted to gain a comprehensive understanding of all the features and relationships in the dataset. Visualizations were used to effectively communicate insights.
* A large number of metrics were considered such as accuracy, logistic loss, precision, recall, F1 score and many others. 
* Vast proportion of machine learning models were used in the process of prediction of churn rate of customers such as Logistic Regression, Decision Tree Classifier, Gaussian Naive Bayes, Random Forest Classifier and XGBoost Regressor.
* Finally, the best model was selected and was __hyperparameter tuned__ to get the best results on the data that the models have not seen before. 

## ğŸ—£ğŸ“£ My Natural Language Processing (NLP) projects

<img src = "https://github.com/sankethkaruturi/Images/blob/390b56e9852ab8948ab08ba551f9a8a7cd7ffdd1/download%20(1).gif" width = "750"/>

__Natural Language Processing (NLP)__ is converting a natural text into a form that could be used for machine learning and deep learning purposes. It involves extracting texts, removing stopwords, lemmatization and stemming, lowercasing the letters, and removing punctuations and other text information that do not add a lot of meaning in our machine learning predictions. Below are the links to some of the Natural Language Processing (NLP) projects.

ğŸ“š [__Predicting Readability of Texts Using Machine Learning__](https://github.com/sankethkaruturi/Predicting-Readability-of-Texts-Using-Machine-Learning.git)     

* Text mining, data visualization, and machine learning can reveal useful insights in the vast amount of text that surrounds us, making it more actionable and useful.
* In addition to this, understanding the difficulty of the text and whether it is at our level could give us good knowledge about the depth of the article.
* Moreover, __libraries__ and other educational institutions could use this information and classify textbooks and notebooks, and separate them based on the difficulty level.
* In this project, machine learning and deep learning algorithms were used to predict the difficulty of texts.
* __Hyperparameter tuning__ was also done to ensure that the models took important features into consideration and made predictions with low __mean squared error__ and __mean absolute error__ respectively.

<hr style="border:0.01px solid blue">

ğŸ‘¹ [__Twitter Sentiment Analysis__](https://github.com/sankethkaruturi/Twitter-Sentiment-Analysis.git)   

* In __Twitter__, there are comments made for different posts and tweets. Sometimes, there might be negative comments that would change the course of the direction of certain topics.
* It is important to identify comments and extract key features from the text so that positive and negative comments could be separated.
* In this project, we are going to be extracting useful information from texts and understand key components for differentiating between __positive texts__ and __negative texts__.

<hr style="border:0.01px solid blue">

ğŸ— [__Fake News Prediction__](https://github.com/sankethkaruturi/Fake-News-Detection.git)

* There has been a lot of __fake news__ that is spread to a large number of people on a regular basis, leading to misinformation.
* With the aid of machine learning and data science, it is possible to extract insights from news.
* Classification ML models are used to determine if the given news is fake or not based on a set of factors. 
* Metrics such as accuracy, precision, recall and f1-score are used to analyze different set of algorithms before __deploying__ in production.
* This saves a lot of time for readers as they are not __fed__ with misleading information. 

<hr style="border:0.01px solid blue">

ğŸ” [__Automated Essay Scoring with Transformers__](https://github.com/sankethkaruturi/Automated-Essay-Scoring-AES-Using-Transformers.git)

* __AI__ analyzes student essays for coherence, clarity, and relevance and offers feedback to improve writing skills.
* Deep learning models (Transformers, LSTMs, GRUs, CNNs, and ML) detect visual cues, model coherence, relevance, and identify factors for effective writing in student essays.
* Multiple approaches provide a comprehensive evaluation, empowering educators to give targeted __feedback__ to improve student writing skills.
* Metrics like accuracy, precision, recall, F1 score, and QWK evaluate model performance for classifying essays.

## ğŸ‘€ğŸ‘ My Computer Vision Projects

<img  src = "https://github.com/sankethkaruturi/Images/blob/592b8288d3ac30726f2fff1ee70844e8616720dc/download%20(2).gif" width = "750" />

__Computer Vision__ is a subset of artificial intelligence which gives the computer to perform computations and make predictions on image data. If the image of a cat is given, for instance, the computer vision algorithms would classify whether there is a cat in the image based on a previously labeled set of images. Therefore, it is important to give the right data to the computer vision algorithms in order for them to get the right predictions. 

Computer vision offers immense potential and high demand due to its wide range of applications. The abundance of image and video data creates numerous opportunities for leveraging computer vision tools effectively. Here, I present a selection of intriguing projects I have personally undertaken in the field of computer vision.

ğŸ‹ [__Wheat Disease Detection Using Transfer Learning__](https://github.com/sankethkaruturi/Wheat-Disease-Detection-Using-Deep-and-Transfer-Learning.git) 

* __Wheat__ is commonly available in various forms such as cereals and bread, but it is susceptible to diseases during production.
* Manual identification of wheat diseases is time-consuming for farmers.
* Computer Vision can be utilized to understand and identify different diseases in wheat, leading to significant time savings.
* This technology enables prompt identification of diseases and facilitates preventive measures for future occurrences.
* Several Convolutional Neural Networks (CNNs) like InceptionV3, Xception, and VGG19 were tested to detect wheat diseases.
* VGG19 exhibited exceptional performance, achieving a test accuracy of 97 percent.

<hr style="border:0.01px solid blue">

ğŸ¥„ [__Steel Defect Detection__](https://github.com/sankethkaruturi/Steel-Defect-Detection-.git)      

* Steel industries produce large quantities of steel, but unnoticed defects can impact quality and lead to issues like **corrosion**.
* Manual defect detection is time-consuming, necessitating the use of analysis and prediction mechanisms.
* Convolutional Neural Networks (CNNs) can generate **predictions** based on past training examples.
* Machine learning models, particularly deep learning models, save time and effort by predicting and addressing steel defects.

<hr style="border:0.01px solid blue">

ğŸŒ¾ [__Wheat Localization With Convolutional Neural Networks (CNNs)__](https://github.com/sankethkaruturi/Wheat-Localization-with-CNN-s.git)    
* There are a lot of food products that we get from wheat.
* Wheat is known as the common food staple that could be used to prepare different kinds of food items.
* Since there are different types of wheat available, it is important to identify different kinds of wheat available.
* In the machine learning project, images of different kinds of __wheat heads__ are taken and made available so that computer vision could be used to understand wheat heads and distinguish them.
* Various computer vision algorithms are used to identify the wheat heads respectively. 

<hr style="border:0.01px solid blue">

ğŸ”¢ [__MNIST Digits Classification__](https://github.com/sankethkaruturi/MNIST-Digits-Classification.git)   

* MNIST data is quite popular as it is being used for beginning the journey with Convolutional Neural Networks.
* The repository contains an MNIST project that would classify the images into __9 digits__ starting from 0 to 9 respectively.
* There are different configurations of Convolutional Neural Networks being implemented by taking into consideration the cross-entropy loss as the metric for getting the best configuration.

<hr style="border:0.01px solid blue">

ğŸ•¸ [__Convolutional Neural Networks CNN Implementation Using Keras__](https://github.com/sankethkaruturi/Convolutional-Neural-Network-CNN-Implementation-using-Keras.git)

* This is a simple project to implement Convolutional Neural Network and note its working.
* Different layer sizes and different kernels are chosen and trained on a simple dataset. The data that was taken was __MNIST__ which is available in Kaggle.
* There are different kernel sizes considered and outputs are noted using a graph respectively.
* By doing this project, I've learned to use __Keras__ and __Tensorflow__ for building Convolutional Neural Networks (CNNs) respectively.


## ğŸ•¸ğŸ”¨My Web Scraping Projects

__Web scraping__ is the process of extracting data from websites. This data can be used for various purposes, such as data science and machine learning. There are different methods for extracting data from websites, which may be stored in HTML, XML, or JSON formats. To successfully scrape data from the web, it is important to use the appropriate techniques. Some web scraping projects also involve querying information from the web.

ğŸ¿ [__IMDB Movies Web Scraping__]  

* IMDB rating could be used to analyze user engagement with various movies.
* It would be really good if we could be using the tables from the IMDB data and understand the factors impacting the ratings by various users.
* Web scraping was done with the help of various packages in Python and understanding the data respectively.
* One popular library used to understand the data was __BeautifulSoup__ that was important for reading the tables respectively.

<hr style="border:0.01px solid blue">

ğŸ” [__Restaurant Recipes Web Scraping XML__]

* There are a lot of items being ordered in restaurants and shopping malls.
* The information is stored on the internet.
* As a result, this could be used for various machine learning and deep learning purposes.
* __Web scraping__ of the __XML files__ was performed in this project.
* In addition to this, it was also important to determine the paths needed for robust querying of the data.
* All of these steps were performed with the aid of packages in Python.

<hr style="border:0.01px solid blue">

ğŸ® [__Popular Gaming Titles Wikipedia Web Scraping__]

* __Wikipedia__ is a good source of information and is often reliable, especially with the trends.
* __Web scraping__ this information could be handy. Web scraping of Gaming data was performed to extract useful insights from it.
* There were various tables present in Wikipedia. Interest was towards the most trending Games and the overall revenue generated by them.
* It was very interesting to work with the data and understand the games that were in high demand.
 
<hr style="border:0.01px solid blue">

ğŸ” [__JSON file Web Scraping__]  

* There could be many websites that give __APIs__ to implement their work.
* We could take the APIs and also extract the __JSON__ files that are stored using key-value terminology.
* When this is performed and done, we could smartly extract useful features that are important for the machine learning predictions depending on the project at hand.
* You might take a look at this project as it highlights how to gain useful information from a website with JSON data.


## ğŸ“ğŸ“‘ My Work Experience 

ğŸ¢ğŸ‘¨â€ğŸ« [__Machine Learning Engineer__]() | [__Pentachrome Technologies Private Limited | Client : KPIT__](https://www.kpit.com/) *[Aug 2019 - Aug 2022]*

- As a Machine Learning Engineer at Pentachrome Technologies, I was influential in using __state-of-the-art__ machine learning and deep learning models to predict Machine failure based on past history. 
- In addition to this, classical models were also used and compared before deciding the best architecture for supply chain optimization. 
- Finally, the explainable part of artificial intelligence was implemented with the use of various tools. This ensured that the predictions given by various ML models are made interpretable to the business before they take action from them.

<hr style="border:0.01px solid blue">

## ğŸ“–ğŸ§‘â€ My Education

<img src = "https://github.com/sankethkaruturi/Images/blob/a30e27740f46b3f70dce31cde9a27edd0104733e/blossoms-2200.jpg" width = "750"/>

<hr style="border:0.01px solid blue">

ğŸ« [__Oregon State University (School of Electrical Engineering and Computer Science)__](https://engineering.asu.edu) - *Masters in Computer Science*

I pursued a Master's degree in Computer Science at Oregon State University. It was a great experience where I had a solid understanding of working with machine learning and deep learning principles and paradigms. Furthermore, I was also involved in a project where we as a team had to build an Deep Neural Network in real time. It was a great experience where I learned deep learning principles and learned to work in sprints for a different set of tasks respectively. Furthermore, I also completed the data structures and analysis of algorithms course which allowed me to understand the time complexity of various algorithms which was also influential in my understanding of machine learning algorithms respectively. 

<hr style="border:0.01px solid blue">

## ğŸ…ğŸ– My List of Certifications

<img src = "https://github.com/sankethkaruturi/Images/blob/9df1c2f17bfb8e6902286b808fc1415f1df4947b/Project%20Thumbnails/Reach%20For%20It%20Great%20Job%20GIF%20by%20AppExchange.gif" width = 750 />

There are numerous machine learning and data science courses that I went through in order to gain a theoretical understanding of the concepts before their practical implementation in the form of projects. Below are some of my certifications and the contents covered in the course respectively.

ğŸŒ± [__Python for Data Science and Machine Learning__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]() - This course is taught by [Jose Portilla](https://www.udemy.com/user/joseportilla/). It is a course that gave me a very good understanding of Python. Important topics such as data frames, tuples, and lists were discussed in the course. The instructor does a good job of showing the practical implementation of the course along with theory. Therefore, this gave me a good solid understanding of Python which later helped me to build machine learning and deep learning algorithms. 

ğŸŒ± [__Deep Learning Specialization__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]() - This is a really long certification consisting of 5 courses. The courses give a good understanding of deep learning. The courses are taught by [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng). Furthermore, there were videos that were being uploaded about interviews with pioneers in the field of Deep Learning. General tips and advice for machine learning projects are also laid out to ensure that beginners don't make the mistake of performing tasks that may not be required. Overall, I was able to get a good understanding of all the courses and they gave me a good idea about Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Deep Neural Networks, and Long-Short Term Memory (LSTM) networks. Below is the list of 5 courses that are present in the specialization. 

&emsp;&emsp; ğŸ [__Neural Networks and Deep Learning__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) - In the first course of the specialization, [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng) concentrates on Logistic Regression, Shallow Neural Networks, and Deep Neural Networks for performing various computations and getting the results. He first explains the basics of how a neuron performs complex computations which would, in turn, lead to predictions. This course gave me a good understanding of the theory behind the working of activation units in neural networks. 

&emsp;&emsp; ğŸ [__Structuring Machine Learning Projects__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) - It is important to take measures to improve the performance of the deep learning models. In this second course under Deep Learning Specialization, structuring machine learning projects and understanding bias, variance, and practical applications of deep learning are taught by the instructor. Overall, it gave me a good foundation to apply my machine learning knowledge to practical real-time projects. 

&emsp;&emsp; ğŸ [__Sequence Models__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) - In the 3rd course of the specialization, Recurrent Neural Networks (RNNs), Word Embeddings, and Natural Language Processing Techniques are taught by the instructor. Moreover, he gives good clarity of different embedding techniques before giving the data to the deep learning models for predictions. Sequence Models and Attention Mechanism topics are also covered in the course. This gave me a good conceptual and practical understanding of deep learning and data science. 

&emsp;&emsp; ğŸ [__Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization__ ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) - When performing the deep learning computations, it is always a good idea to perform hyperparameter tuning in order to get the best results for our test set. In the course, the importance of regularization and hyperparameter tuning is taught by the instructor. Furthermore, various optimization algorithms are taught by the instructor. All-in-all, it was a good course that covered the important aspects of deep learning in a data science life cycle respectively. 

&emsp;&emsp; ğŸ [__Convolutional Neural Networks__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) - In the final course of the Deep Learning Specialization, the instructor teaches the foundations of Convolutional Neural Networks (CNNs). Also, Deep Convolutional Neural Networks along with case studies are included in the lectures. Finally, Face Recognition Technology and Neural Style Transfer are taught in the course, giving a good idea of their work. Hence, I was able to get a good amount of working knowledge in the field of data science and deep learning by going through all the courses and completing the specialization.

ğŸŒ± [__Machine Learning by Stanford University__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) - This is a course taught by [Andrew Ng](https://en.wikipedia.org/wiki/Andrew_Ng). I was able to understand the theory behind machine learning and deep learning models. Furthermore, he also gives practical advice on how machine learning could be used in different industries. The language that was used for programming was Octave. Overall, this gave me a good understanding of machine learning and I was able to enter the field starting with this course. 

ğŸŒ± [__Data Science and Machine Learning Bootcamp with R__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white) - R is a programming language that could be used for statistical purposes. I was able to implement the machine learning models using R. There are various ways in which R programming language is used in different scenarios. The was taught by [Jose Portilla](https://www.udemy.com/user/joseportilla/). It gave a good insight into using R for machine learning purposes. Most of the videos are focused on the practical implementation of the machine learning models respectively. 

 ğŸŒ± [__Machine Learning Engineering for Production (MLOps) Specialization__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]() - The specialization opens new frontiers in machine learning by teaching set of steps and methodologies in building highly scalable and robust end-to-end machine learning systems. A lot of new topics were covered in the space of MLOps such as model decay, latency, system requirements and many others. The framework used for end-to-end deployment was tensorflow extended (TFX), leading to efficient and highly scalable solutions to various ML problems. 

&emsp;&emsp; ğŸ [__Introduction to Machine Learning in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]() - This course gives examples of how to use various strategies for building machine learning models in production. There are often challenges that go unnoticed if care is not taken when models are put to production. As a result, there is a degradation in their performance. This course does a good job in highlighting this scenario in great detail along with steps to be taken to reduce them.

&emsp;&emsp; ğŸ [__Machine Learning Data Lifecycle in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]() - The course introduces various components in the TensorFlow Extended (TFX) library that is used by end-to-end deployment. Components such as StatisticsGen, SchemaGen, ExampleValidator, and ExamplesGen are used which form the initial pipeline components of TensorFlow Extended. A lot of exercises were given to get a firmer understanding of these components in great detail in many scenarios.

&emsp;&emsp; ğŸ [__Machine Learning Modeling Pipelines in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]() - This course teaches the best practices to follow when building data pipelines for machine learning. Depending on the size and complexity of the network, various set of practices must be followed in order for the models to work well in specific platforms.  

&emsp;&emsp; ğŸ [__Deploying Machine Learning Models in Production__  ![](https://img.shields.io/badge/Coursera-0056D2?style=for-the-badge&logo=Coursera&logoColor=white) ]() - This course primarily deals with building and deploying machine learning models in production. Knowledge about various inference engines and serving mechanisms were explained and demonstrated well. Kubernetes and docker were used as important tools for ML deployment along with providing the right security features for different network topologies. 

ğŸŒ± [__Complete Tensorflow 2 and Keras Deep Learning Bootcamp__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]() - Deep learning has been gaining traction in the recent decade. I could see that most of the projects on Kaggle are done with Tensorflow and Pytorch. The course is taught by [Jose Portilla](https://www.udemy.com/user/joseportilla/) from Udemy. Most of the course is focused on the implementation of deep learning using Keras and Tensorflow. I got a good understanding of implementing various deep-learning projects using Keras and Tensorflow.

ğŸŒ± [__Deploying AI & Machine Learning Models for Business | Python__ ![]() - This course teaches the fundamentals of Docker and explains them in detail. In addition, the instructor does a good job in explaining how Docker along with Flask and Apache could be used for deploying our machine learning models and making them highly scalable. It also talks about various errors that can occur during the production environment that is important to consider when trying to deploy machine learning models to a large number of clients and users. 

ğŸŒ± [__Python for Time Series Data Analysis__ ![](https://img.shields.io/badge/Udemy-EC5252?style=for-the-badge&logo=Udemy&logoColor=white)]() - This course emphasizes the construction of time series models using up-to-date data from diverse sources. Participants gain a comprehensive understanding of cutting-edge models, including ARMA, ARIMA, SARIMA, SARIMAX, and Deep Neural Networks, for accurate forecasting. The course is highly regarded, offering clear explanations of the concepts and delivering valuable insights.

## ğŸğŸ Competencies

<img src = "https://github.com/sankethkaruturi/Images/blob/03b1f06d7875e87c149bedea379ed64c317112c6/Project%20Thumbnails/competencies.jpg" width = "750" />

ğŸ¦¸ [__Leadership Skills__]() 

* During my B.tech in India, I had an opportunity to direct a team of students in our final project proposal. 
* It was a good opportunity for me to improve my leadership skills during the process. 
* I improved my knowledge in the field of machine learning and also learned the skills needed to direct people so that we get the best results respectively. 

<hr style="border:0.01px solid blue">

ğŸ¦¸ [__Communication Skills__]()

* Communication skills are also important to become a good software engineer and a data scientist. 
* Communication plays a very important role when it comes to letting others in the team know the progress, tracking the development of a project, and getting a good understanding of the overall flow of the team. 
* I built my communication skills during my masters where I had to discuss my assignments and projects and let them know the overall scenario where our project could be used. 
* Furthermore, I've gone through courses that are related to communication which would ensure that we are getting the best results when talking to a group of people or an audience respectively. 

<hr style="border:0.01px solid blue">

ğŸ¦¸ [__Team Work__]() 

* When building projects and talking to people about the outcomes, it is important to have teamwork so that it would be a whole lot easier for a team to improve the performance of the company. 
* That's the reason why companies such as Apple and Facebook are improving their revenue as a result of work from the team rather than individual efforts. 
* Given my strong involvement in teams, I have actively participated in numerous team-based projects, honing my networking and team management skills along the way. 

<hr style="border:0.01px solid blue">

ğŸ¦¸ [__Curiosity__]()

* Being creative when building applications would lead to better and more innovative products. 
* Some of the most remarkable breakthroughs take place with curiosity in the field. 
* I believe that having high levels of curiosity in endeavors could lead to better outcomes not only in the short run but in the long run as well. 

<hr style="border:0.01px solid blue">

ğŸ¦¸ [__Problem-solving Skills__]()

* These are the skills that generally help in solving issues quickly and effectively. 
* They are being learned as part of education or training. 
* They are generally about familiarizing themselves with the common issues in various industries and also learning from experienced employees. 

<hr style="border:0.01px solid blue">

ğŸ¦¸ [__Time Management__]() 

* During my tenure at [Pentachrome Technologies](), I earned a professional reputation by learning to manage time and giving the best outcomes for the company by working smart and trying to get things done in less time. 
* Therefore, I was involved in the process of organizing and planning various activities. 
* As a result, there was very good productivity in the company by managing time and effectively using it for best practices. 

## ğŸ˜‡ğŸ˜‡ My Values:

![](https://github.com/sankethkaruturi/Images/blob/4518418fb108faaed36c05c2c93ff0b7b4058df1/Project%20Thumbnails/latestgiffile.gif)

There is a lot of __resources__ and __tools__ available in the world with the advancement of technology. I believe that __education__ should be accessible to everyone regardless of their __location__, __age__ and __social status__. It is possible to discover very good insights with the help of __machine learning__ and __data science__ and use them to serve education in different parts of the world. I also believe that each and every individual is unique and outstanding in his/her ways. Each and every individual must be respected regardless of their conditions or their significance in society. All in all, I believe that one must give respect to each other and this would ensure that we go in the right direction and make a significant impact in society. 

## ğŸ¼ğŸ‘¨â€ğŸ“ Key Learnings

<img src = "https://github.com/sankethkaruturi/Images/blob/4ce95f1c3684d28ec7cd36619f33be43a5f934bf/Project%20Thumbnails/kelly-sikkema-ml1IgjV8OvY-unsplash.jpg" width = "750"/>

During my machine learning journey, I had a good time learning important things and takeaways while implementing and executing various projects. As a result, I was able to learn iteratively and update my knowledge of the latest technologies and tools used in the process of building interesting AI-powered applications. Given below are some of the repositories that I have added that I felt had key ingredients in them that helped me excel in this data science journey. 

ğŸ“½ [__Jose Portilla's Reinforcement Learning Course__]() - One of the interesting things about the instructor [Jose Portilla](https://www.udemy.com/user/joseportilla/) is his attention to detail and clarity of explanation. Reinforcement learning has a lot of potential, especially in database systems and computer systems. After going through the course, I learned a lot of intricate details about how to define an agent and an environment which are the key tools in reinforcement learning. You might take a look at the repository where I present the notebooks which were used for learning the basics and advanced concepts related to python. 


## ğŸ”¬ğŸ§ My Thoughts on State-of-the-art (SOTA) Techniques in Artificial Intelligence

<img src = "https://github.com/sankethkaruturi/Images/blob/17ccddf951df208fcce19a038a6d2ad5878acae5/Project%20Thumbnails/animation%20illustration%20GIF%20by%20Tony%20Babel.gif" width = "750"/>

There is a large volume of research taking place in the field of machine learning and data science. There are newer and computationally efficient algorithms being developed by the likes of many companies and research institutes. I would like to share my thoughts on these latest machine learning trends and explain them well. 

&emsp;&emsp; ğŸ‘€ğŸ‘ [__Vision Transformers (ViTs)__](https://en.wikipedia.org/wiki/Vision_transformer) - Transformers have revolutionized the __natural language processing industry (NLP)__ where a given text is converted into a representation that takes into account the contextual information for all the possible words given as input and returns a vector with these weights and other dependencies. One interesting research area that has emerged is to use of these same transformers for computer vision tasks. __Convolutional Neural Networks__, CNNs for short, are currently being used to take into account different positions of the image and map them with their weights before making predictions. But if we could represent these vectors by using contextual dependencies, then vision transformers might be able to replace CNNs in the future. Currently, as the performance of vision transformers has not been significantly higher than the CNN models, there is no replacement for CNNs. However, as the complexity of vision transformers increases, there is a possibility that they might replace CNNs for image processing tasks.

&emsp;&emsp; ğŸ“£ğŸ”Š [__LIME &__](https://homes.cs.washington.edu/~marcotcr/blog/lime/) [__SHAP (Explainable AI)__](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html) - __LIME__ stands for __Local Interpretable Model-agnostic Explanations__ while __SHAP__ stands for __Shapley Additive Explanations__. One of the challenges with using AI and machine learning, in general, is their lack of interpretability. Though there are models such as Random Forests and Decision trees that explain why they have come up with a particular outcome such as giving feature importance, they fail to account for local dependencies which means they do not give output for a particular query point but only provide explainability in terms of the entire dataset. Furthermore, there are other models that do not also offer these features. With the help of LIME and SHAP, it is possible to explain for a query point why a particular outcome is generated for any of the machine learning models at hand. Therefore, LIME and SHAP are good, and executing them is also a lot easier with the help of libraries.

&emsp;&emsp; ğŸ“•ğŸ“š [__BERT &__](https://en.wikipedia.org/wiki/BERT_(language_model)) [__RoBERTa__](https://ai.facebook.com/blog/roberta-an-optimized-method-for-pretraining-self-supervised-nlp-systems/) - __BERT__ stands for __Bidirectional Encoder Representations from Transformers__ while __RoBERTa__ stands for __Robustly Optimized BERT Pre-training Approach__. These models have been gaining popularity due to their extremely good performance in natural language processing tasks. They are basically transformers with bidirectional context vector representation. In other words, they take into account the context in terms of both the forward pass and the backward pass as well. This works extremely well due to the fact that representing each word based on the context of all the words in the document is basically a good way to understand human language. 

&emsp;&emsp; ğŸ”ğŸ”¦ [__FAISS &__](https://ai.facebook.com/tools/faiss/) [__ScaNN__](https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html) - When we are dealing with finding similar rows in our data and we have a very high dimensional representation of a vector, with traditional algorithms it takes a long time to find similarly if we use metrics such as __euclidean distance__ and __cosine similarity__. __Facebook Research__ has launched __FAISS__ that simplifies the process of searching for similarity and clustering of dense vectors. In the same light, __Google AI Research__ came up with __ScaNN__ which speeds up the overall process of computing the distance between various features and reduces the time complexity to a large extent. The outputs from these models contain vectors that represent a large amount of information from the input data. These are useful for building __good recommender systems__ where the items that are the most similar are recommended to a user along with many other applications as well.

&emsp;&emsp; ğŸ§ğŸ”‰ [__Audio Signal as a Spectrogram__](https://en.wikipedia.org/wiki/Spectrogram#:~:text=A%20spectrogram%20is%20a%20visual,may%20be%20called%20waterfall%20displays.) - We can define our audio signal in terms of a __spectrogram__ which is used in __audio processing__. One of the most insightful things that are currently done for deep learning is that an audio signal is converted to a spectrogram image which is later used with __convolutional neural networks (CNNs)__ for NLP tasks. Therefore, we are trying to pose the audio problem as a computer vision problem and get __higher accuracy__ and __better results__. __CNNs__ are known to perform especially well if we are able to give large amounts of image data. CNN along with transfer learning produces extremely good results. Therefore, it is improving the performance of NLP tasks such as __speech detection__ and many others. 

&emsp;&emsp; ğŸ¤ğŸ•¸  [__Siamese Networks__](https://en.wikipedia.org/wiki/Siamese_neural_network) - Building __recommender systems__ whether it be __recommending items__, __movies__, or __songs__ with the help of deep neural networks can be a hard problem to define and solve respectively. With the help of __Siamese neural networks__, it is possible to use deep learning for recommending users various items as discussed above. __Siamese networks__ essentially take into account __2 different inputs__ and they have __2 networks__ that accept these inputs. The same weights are initialized to both networks and the __outputs__ from these two networks are combined together to get our predictions of how likely is the user going to like a particular item. Furthermore, it is also possible to perform __one-shot learning__ with these models which means that with few training examples, the model would learn to perform the best for the task at hand.


## ğŸ¬ğŸ”š Summary

These are some of my __projects__, __blogs__ and __certifications__ that I have worked on and uploaded on __GitHub__. I would be looking forward to learning new technologies in the field of __AI__ and __machine learning__ by going through a few more courses and applying my knowledge to different projects. Feel free to reach out if you have any questions or need any explanations of the projects. Looking forward to sharing my knowledge with the community.

Below are some of the ways we might connect. Feel free to share your thoughts. Thanks!ğŸ˜

ğŸ–‡ __LinkedIn:__ __https://www.linkedin.com/in/sanketh-karuturi__

ğŸ“« __Email:__ __sankethkaruturi09@gmail.com__

âœğŸ» __Medium:__ __https://medium.com/@sankethkaruturi09__


ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„ğŸ˜„


